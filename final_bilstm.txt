Training new model, loss:binary_crossentropy, optimizer=nadam, lstm_len=256, dropoff=0.6
Epoch 1/20
 - 4s - loss: 0.6613 - acc: 0.5930
Epoch 2/20
 - 1s - loss: 0.6595 - acc: 0.6800
Epoch 3/20
 - 1s - loss: 0.6328 - acc: 0.6859
Epoch 4/20
 - 1s - loss: 0.5631 - acc: 0.7084
Epoch 5/20
 - 1s - loss: 0.5408 - acc: 0.7260
Epoch 6/20
 - 1s - loss: 0.5173 - acc: 0.7370
Epoch 7/20
 - 1s - loss: 0.4962 - acc: 0.7495
Epoch 8/20
 - 1s - loss: 0.4843 - acc: 0.7566
Epoch 9/20
 - 1s - loss: 0.4750 - acc: 0.7631
Epoch 10/20
 - 1s - loss: 0.4747 - acc: 0.7639
Epoch 11/20
 - 1s - loss: 0.4636 - acc: 0.7694
Epoch 12/20
 - 1s - loss: 0.4606 - acc: 0.7731
Epoch 13/20
 - 1s - loss: 0.4711 - acc: 0.7686
Epoch 14/20
 - 1s - loss: 0.4584 - acc: 0.7725
Epoch 15/20
 - 1s - loss: 0.4478 - acc: 0.7809
Epoch 16/20
 - 1s - loss: 0.4437 - acc: 0.7845
Epoch 17/20
 - 1s - loss: 0.4380 - acc: 0.7872
Epoch 18/20
 - 1s - loss: 0.4304 - acc: 0.7922
Epoch 19/20
 - 1s - loss: 0.4275 - acc: 0.7916
Epoch 20/20
 - 1s - loss: 0.4168 - acc: 0.7985

  32/3329 [..............................] - ETA: 15s
 128/3329 [>.............................] - ETA: 5s 
 224/3329 [=>............................] - ETA: 3s
 320/3329 [=>............................] - ETA: 3s
 416/3329 [==>...........................] - ETA: 2s
 512/3329 [===>..........................] - ETA: 2s
 608/3329 [====>.........................] - ETA: 2s
 704/3329 [=====>........................] - ETA: 2s
 800/3329 [======>.......................] - ETA: 2s
 896/3329 [=======>......................] - ETA: 1s
 992/3329 [=======>......................] - ETA: 1s
1088/3329 [========>.....................] - ETA: 1s
1184/3329 [=========>....................] - ETA: 1s
1280/3329 [==========>...................] - ETA: 1s
1376/3329 [===========>..................] - ETA: 1s
1472/3329 [============>.................] - ETA: 1s
1568/3329 [=============>................] - ETA: 1s
1664/3329 [=============>................] - ETA: 1s
1760/3329 [==============>...............] - ETA: 1s
1856/3329 [===============>..............] - ETA: 1s
1952/3329 [================>.............] - ETA: 1s
2048/3329 [=================>............] - ETA: 0s
2144/3329 [==================>...........] - ETA: 0s
2240/3329 [===================>..........] - ETA: 0s
2336/3329 [====================>.........] - ETA: 0s
2432/3329 [====================>.........] - ETA: 0s
2528/3329 [=====================>........] - ETA: 0s
2624/3329 [======================>.......] - ETA: 0s
2720/3329 [=======================>......] - ETA: 0s
2816/3329 [========================>.....] - ETA: 0s
2912/3329 [=========================>....] - ETA: 0s
3008/3329 [==========================>...] - ETA: 0s
3104/3329 [==========================>...] - ETA: 0s
3200/3329 [===========================>..] - ETA: 0s
3296/3329 [============================>.] - ETA: 0s
3329/3329 [==============================] - 2s 720us/step
[0.43345030870979057, 0.7945328927605888]
recall: array([0.78485577, 0.8042042 ])
precision: array([0.8002451 , 0.78903948])
true count:array([1664, 1665])
predict count:array([1632, 1697])

Training new model, loss:binary_crossentropy, optimizer=nadam, lstm_len=256, dropoff=0.55
Epoch 1/20
 - 2s - loss: 0.6746 - acc: 0.5959
Epoch 2/20
 - 1s - loss: 0.6256 - acc: 0.6910
Epoch 3/20
 - 1s - loss: 0.5435 - acc: 0.7221
Epoch 4/20
 - 1s - loss: 0.5307 - acc: 0.7249
Epoch 5/20
 - 1s - loss: 0.5195 - acc: 0.7330
Epoch 6/20
 - 1s - loss: 0.4949 - acc: 0.7485
Epoch 7/20
 - 1s - loss: 0.4867 - acc: 0.7556
Epoch 8/20
 - 1s - loss: 0.4793 - acc: 0.7589
Epoch 9/20
 - 1s - loss: 0.4693 - acc: 0.7642
Epoch 10/20
 - 1s - loss: 0.4634 - acc: 0.7711
Epoch 11/20
 - 1s - loss: 0.4573 - acc: 0.7747
Epoch 12/20
 - 1s - loss: 0.4505 - acc: 0.7770
Epoch 13/20
 - 1s - loss: 0.4432 - acc: 0.7830
Epoch 14/20
 - 1s - loss: 0.4369 - acc: 0.7829
Epoch 15/20
 - 1s - loss: 0.4280 - acc: 0.7905
Epoch 16/20
 - 1s - loss: 0.4223 - acc: 0.7950
Epoch 17/20
 - 1s - loss: 0.4176 - acc: 0.7982
Epoch 18/20
 - 1s - loss: 0.4167 - acc: 0.8014
Epoch 19/20
 - 1s - loss: 0.4078 - acc: 0.8039
Epoch 20/20
 - 1s - loss: 0.4028 - acc: 0.8103

  32/3329 [..............................] - ETA: 19s
 128/3329 [>.............................] - ETA: 6s 
 224/3329 [=>............................] - ETA: 4s
 320/3329 [=>............................] - ETA: 3s
 416/3329 [==>...........................] - ETA: 3s
 512/3329 [===>..........................] - ETA: 2s
 608/3329 [====>.........................] - ETA: 2s
 704/3329 [=====>........................] - ETA: 2s
 800/3329 [======>.......................] - ETA: 2s
 896/3329 [=======>......................] - ETA: 2s
 992/3329 [=======>......................] - ETA: 1s
1088/3329 [========>.....................] - ETA: 1s
1184/3329 [=========>....................] - ETA: 1s
1280/3329 [==========>...................] - ETA: 1s
1376/3329 [===========>..................] - ETA: 1s
1472/3329 [============>.................] - ETA: 1s
1568/3329 [=============>................] - ETA: 1s
1664/3329 [=============>................] - ETA: 1s
1760/3329 [==============>...............] - ETA: 1s
1856/3329 [===============>..............] - ETA: 1s
1952/3329 [================>.............] - ETA: 1s
2048/3329 [=================>............] - ETA: 0s
2144/3329 [==================>...........] - ETA: 0s
2240/3329 [===================>..........] - ETA: 0s
2336/3329 [====================>.........] - ETA: 0s
2432/3329 [====================>.........] - ETA: 0s
2528/3329 [=====================>........] - ETA: 0s
2624/3329 [======================>.......] - ETA: 0s
2720/3329 [=======================>......] - ETA: 0s
2816/3329 [========================>.....] - ETA: 0s
2912/3329 [=========================>....] - ETA: 0s
3008/3329 [==========================>...] - ETA: 0s
3104/3329 [==========================>...] - ETA: 0s
3200/3329 [===========================>..] - ETA: 0s
3296/3329 [============================>.] - ETA: 0s
3329/3329 [==============================] - 2s 728us/step
[0.4326593615730162, 0.7921297686993091]
recall: array([0.80528846, 0.77897898])
precision: array([0.78454333, 0.80012338])
true count:array([1664, 1665])
predict count:array([1708, 1621])

Training new model, loss:binary_crossentropy, optimizer=nadam, lstm_len=128, dropoff=0.4
Epoch 1/20
 - 2s - loss: 0.6734 - acc: 0.5894
Epoch 2/20
 - 1s - loss: 0.5972 - acc: 0.6807
Epoch 3/20
 - 1s - loss: 0.5597 - acc: 0.7117
Epoch 4/20
 - 1s - loss: 0.5415 - acc: 0.7219
Epoch 5/20
 - 1s - loss: 0.5267 - acc: 0.7319
Epoch 6/20
 - 1s - loss: 0.5016 - acc: 0.7490
Epoch 7/20
 - 1s - loss: 0.4871 - acc: 0.7535
Epoch 8/20
 - 1s - loss: 0.4751 - acc: 0.7620
Epoch 9/20
 - 1s - loss: 0.4905 - acc: 0.7539
Epoch 10/20
 - 1s - loss: 0.4651 - acc: 0.7687
Epoch 11/20
 - 1s - loss: 0.4566 - acc: 0.7784
Epoch 12/20
 - 1s - loss: 0.4498 - acc: 0.7815
Epoch 13/20
 - 1s - loss: 0.4448 - acc: 0.7831
Epoch 14/20
 - 1s - loss: 0.4414 - acc: 0.7863
Epoch 15/20
 - 1s - loss: 0.4333 - acc: 0.7900
Epoch 16/20
 - 1s - loss: 0.4313 - acc: 0.7894
Epoch 17/20
 - 1s - loss: 0.4243 - acc: 0.7954
Epoch 18/20
 - 1s - loss: 0.4179 - acc: 0.7936
Epoch 19/20
 - 1s - loss: 0.4169 - acc: 0.7979
Epoch 20/20
 - 1s - loss: 0.4141 - acc: 0.7999

  32/3329 [..............................] - ETA: 24s
 128/3329 [>.............................] - ETA: 7s 
 224/3329 [=>............................] - ETA: 5s
 320/3329 [=>............................] - ETA: 3s
 416/3329 [==>...........................] - ETA: 3s
 512/3329 [===>..........................] - ETA: 2s
 608/3329 [====>.........................] - ETA: 2s
 704/3329 [=====>........................] - ETA: 2s
 800/3329 [======>.......................] - ETA: 2s
 896/3329 [=======>......................] - ETA: 2s
 992/3329 [=======>......................] - ETA: 2s
1088/3329 [========>.....................] - ETA: 1s
1184/3329 [=========>....................] - ETA: 1s
1280/3329 [==========>...................] - ETA: 1s
1376/3329 [===========>..................] - ETA: 1s
1472/3329 [============>.................] - ETA: 1s
1568/3329 [=============>................] - ETA: 1s
1664/3329 [=============>................] - ETA: 1s
1760/3329 [==============>...............] - ETA: 1s
1856/3329 [===============>..............] - ETA: 1s
1952/3329 [================>.............] - ETA: 1s
2048/3329 [=================>............] - ETA: 0s
2144/3329 [==================>...........] - ETA: 0s
2240/3329 [===================>..........] - ETA: 0s
2336/3329 [====================>.........] - ETA: 0s
2432/3329 [====================>.........] - ETA: 0s
2528/3329 [=====================>........] - ETA: 0s
2624/3329 [======================>.......] - ETA: 0s
2720/3329 [=======================>......] - ETA: 0s
2816/3329 [========================>.....] - ETA: 0s
2912/3329 [=========================>....] - ETA: 0s
3008/3329 [==========================>...] - ETA: 0s
3104/3329 [==========================>...] - ETA: 0s
3200/3329 [===========================>..] - ETA: 0s
3296/3329 [============================>.] - ETA: 0s
3329/3329 [==============================] - 2s 732us/step
[0.42493253860361907, 0.7978371883448483]
recall: array([0.79747596, 0.7981982 ])
precision: array([0.7979555 , 0.79771909])
true count:array([1664, 1665])
predict count:array([1663, 1666])

Training new model, loss:binary_crossentropy, optimizer=nadam, lstm_len=128, dropoff=0.45
Epoch 1/20
 - 2s - loss: 0.6602 - acc: 0.5981
Epoch 2/20
 - 1s - loss: 0.5843 - acc: 0.6913
Epoch 3/20
 - 1s - loss: 0.5443 - acc: 0.7154
Epoch 4/20
 - 1s - loss: 0.5160 - acc: 0.7372
Epoch 5/20
 - 1s - loss: 0.4985 - acc: 0.7465
Epoch 6/20
 - 1s - loss: 0.4875 - acc: 0.7549
Epoch 7/20
 - 1s - loss: 0.4917 - acc: 0.7521
Epoch 8/20
 - 1s - loss: 0.4766 - acc: 0.7622
Epoch 9/20
 - 1s - loss: 0.4698 - acc: 0.7644
Epoch 10/20
 - 1s - loss: 0.4571 - acc: 0.7746
Epoch 11/20
 - 1s - loss: 0.4507 - acc: 0.7782
Epoch 12/20
 - 1s - loss: 0.4456 - acc: 0.7810
Epoch 13/20
 - 1s - loss: 0.4320 - acc: 0.7916
Epoch 14/20
 - 1s - loss: 0.4253 - acc: 0.7929
Epoch 15/20
 - 1s - loss: 0.4210 - acc: 0.7949
Epoch 16/20
 - 1s - loss: 0.4136 - acc: 0.7997
Epoch 17/20
 - 1s - loss: 0.4066 - acc: 0.8036
Epoch 18/20
 - 1s - loss: 0.4020 - acc: 0.8087
Epoch 19/20
 - 1s - loss: 0.3959 - acc: 0.8130
Epoch 20/20
 - 1s - loss: 0.3879 - acc: 0.8154

  32/3329 [..............................] - ETA: 28s
 128/3329 [>.............................] - ETA: 8s 
 224/3329 [=>............................] - ETA: 5s
 320/3329 [=>............................] - ETA: 4s
 416/3329 [==>...........................] - ETA: 3s
 512/3329 [===>..........................] - ETA: 3s
 608/3329 [====>.........................] - ETA: 2s
 704/3329 [=====>........................] - ETA: 2s
 800/3329 [======>.......................] - ETA: 2s
 864/3329 [======>.......................] - ETA: 2s
 960/3329 [=======>......................] - ETA: 2s
1056/3329 [========>.....................] - ETA: 2s
1152/3329 [=========>....................] - ETA: 1s
1248/3329 [==========>...................] - ETA: 1s
1344/3329 [===========>..................] - ETA: 1s
1440/3329 [===========>..................] - ETA: 1s
1536/3329 [============>.................] - ETA: 1s
1632/3329 [=============>................] - ETA: 1s
1728/3329 [==============>...............] - ETA: 1s
1824/3329 [===============>..............] - ETA: 1s
1920/3329 [================>.............] - ETA: 1s
2016/3329 [=================>............] - ETA: 1s
2112/3329 [==================>...........] - ETA: 0s
2208/3329 [==================>...........] - ETA: 0s
2304/3329 [===================>..........] - ETA: 0s
2400/3329 [====================>.........] - ETA: 0s
2496/3329 [=====================>........] - ETA: 0s
2592/3329 [======================>.......] - ETA: 0s
2688/3329 [=======================>......] - ETA: 0s
2784/3329 [========================>.....] - ETA: 0s
2880/3329 [========================>.....] - ETA: 0s
2976/3329 [=========================>....] - ETA: 0s
3072/3329 [==========================>...] - ETA: 0s
3168/3329 [===========================>..] - ETA: 0s
3264/3329 [============================>.] - ETA: 0s
3329/3329 [==============================] - 3s 768us/step
[0.41157722183088885, 0.8098528086512466]
recall: array([0.78966346, 0.83003003])
precision: array([0.82279274, 0.79792148])
true count:array([1664, 1665])
predict count:array([1597, 1732])

Training new model, loss:binary_crossentropy, optimizer=adam, lstm_len=256, dropoff=0.55
Epoch 1/20
 - 3s - loss: 0.6739 - acc: 0.5828
Epoch 2/20
 - 1s - loss: 0.5929 - acc: 0.6895
Epoch 3/20
 - 1s - loss: 0.5562 - acc: 0.7107
Epoch 4/20
 - 1s - loss: 0.5250 - acc: 0.7329
Epoch 5/20
 - 1s - loss: 0.5187 - acc: 0.7321
Epoch 6/20
 - 1s - loss: 0.5021 - acc: 0.7442
Epoch 7/20
 - 1s - loss: 0.5029 - acc: 0.7435
Epoch 8/20
 - 1s - loss: 0.4951 - acc: 0.7447
Epoch 9/20
 - 1s - loss: 0.4850 - acc: 0.7556
Epoch 10/20
 - 1s - loss: 0.4810 - acc: 0.7586
Epoch 11/20
 - 1s - loss: 0.4796 - acc: 0.7613
Epoch 12/20
 - 1s - loss: 0.4693 - acc: 0.7660
Epoch 13/20
 - 1s - loss: 0.4593 - acc: 0.7734
Epoch 14/20
 - 1s - loss: 0.4492 - acc: 0.7828
Epoch 15/20
 - 1s - loss: 0.4451 - acc: 0.7848
Epoch 16/20
 - 1s - loss: 0.4386 - acc: 0.7888
Epoch 17/20
 - 1s - loss: 0.4314 - acc: 0.7929
Epoch 18/20
 - 1s - loss: 0.4288 - acc: 0.7954
Epoch 19/20
 - 1s - loss: 0.4267 - acc: 0.7962
Epoch 20/20
 - 1s - loss: 0.4184 - acc: 0.8030

  32/3329 [..............................] - ETA: 33s
 128/3329 [>.............................] - ETA: 9s 
 224/3329 [=>............................] - ETA: 6s
 320/3329 [=>............................] - ETA: 5s
 416/3329 [==>...........................] - ETA: 4s
 512/3329 [===>..........................] - ETA: 3s
 608/3329 [====>.........................] - ETA: 3s
 704/3329 [=====>........................] - ETA: 2s
 800/3329 [======>.......................] - ETA: 2s
 896/3329 [=======>......................] - ETA: 2s
 992/3329 [=======>......................] - ETA: 2s
1088/3329 [========>.....................] - ETA: 2s
1152/3329 [=========>....................] - ETA: 2s
1248/3329 [==========>...................] - ETA: 1s
1344/3329 [===========>..................] - ETA: 1s
1440/3329 [===========>..................] - ETA: 1s
1536/3329 [============>.................] - ETA: 1s
1632/3329 [=============>................] - ETA: 1s
1728/3329 [==============>...............] - ETA: 1s
1824/3329 [===============>..............] - ETA: 1s
1920/3329 [================>.............] - ETA: 1s
2016/3329 [=================>............] - ETA: 1s
2112/3329 [==================>...........] - ETA: 1s
2208/3329 [==================>...........] - ETA: 0s
2304/3329 [===================>..........] - ETA: 0s
2400/3329 [====================>.........] - ETA: 0s
2496/3329 [=====================>........] - ETA: 0s
2592/3329 [======================>.......] - ETA: 0s
2688/3329 [=======================>......] - ETA: 0s
2784/3329 [========================>.....] - ETA: 0s
2880/3329 [========================>.....] - ETA: 0s
2976/3329 [=========================>....] - ETA: 0s
3072/3329 [==========================>...] - ETA: 0s
3168/3329 [===========================>..] - ETA: 0s
3264/3329 [============================>.] - ETA: 0s
3329/3329 [==============================] - 3s 783us/step
[0.4410155027898878, 0.793631721237609]
recall: array([0.80528846, 0.78198198])
precision: array([0.78684674, 0.80073801])
true count:array([1664, 1665])
predict count:array([1703, 1626])

