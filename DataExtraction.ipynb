{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare valid hindi literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_hindi = list(set(list(\"ऀँंःऄअआइईउऊऋऌऍऎएऐऑऒओऔकखगघङचछजझञटठडढणतथदधनऩपफबभमयरऱलळऴवशषसहऺऻ़ऽािीुूृॄॅॆेैॉॊोौ्ॎॏॐ॒॑॓॔ॕॖॗक़ख़ग़ज़ड़ढ़फ़य़ॠॡॢॣ।॥॰ॱॲॳॴॵॶॷॸॹॺॻॼॽॾॿ-\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse Hindimonocop05.export file and create a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ec5372db3242709705172e33438257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "genderList = set()\n",
    "ind = 0\n",
    "with open('C:\\\\Users\\\\archi\\\\Downloads\\\\hindmonocorp05.export\\\\hindmonocorp05.export',encoding='utf-8') as infile:\n",
    "    for line in tqdm_notebook(infile):\n",
    "        #print(line.replace('\\t',' ').split(' '))\n",
    "        cs = line.replace('\\t',' ').split(' ')\n",
    "        ind = ind + 1\n",
    "        for c in cs:\n",
    "            if c[0] in valid_hindi:\n",
    "                d = c.split('|')\n",
    "                e = d[2].split('.')\n",
    "                if len(e) < 3:\n",
    "                    continue\n",
    "                if e[2] == 'm':\n",
    "                    genderList.add((d[0],'m'))\n",
    "                elif e[2] == 'f':\n",
    "                    genderList.add((d[0],'f'))\n",
    "                elif e[2] == 'any':\n",
    "                    genderList.add((d[0],'any'))\n",
    "                else:\n",
    "                    genderList.add((d[0],'none'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "genderList = list(genderList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "genderList.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "genderListCleared = []\n",
    "for item in genderList:\n",
    "    exit = False\n",
    "    for ch in item[0]:\n",
    "        if ch not in valid_hindi:\n",
    "            exit = True\n",
    "    if exit:\n",
    "        continue\n",
    "    genderListCleared.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mCount = 0\n",
    "fCount = 0\n",
    "nCount = 0\n",
    "for item in genderListCleared:\n",
    "    if item[1] == 'm':\n",
    "        mCount+=1\n",
    "    elif item[1] == 'f':\n",
    "        fCount+=1\n",
    "    elif item[1] == 'none':\n",
    "        nCount+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21432, 11381, 248908, 9151)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mCount,fCount,nCount,len(genderListCleared)-mCount-fCount-nCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort conflicts in the hindimonocorp by giving none higher priority and then any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ind in range(0, len(genderListCleared)-1):\n",
    "    if genderListCleared[ind][0] == genderListCleared[ind+1][0]:\n",
    "        genderListCleared[ind] = genderListCleared[ind][0], 'any'\n",
    "        genderListCleared[ind+1] = genderListCleared[ind][0], 'any'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290872, 284250)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genderListCleared),len(set(genderListCleared))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "genderListCleared = list(set(genderListCleared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mCount = 0\n",
    "fCount = 0\n",
    "nCount = 0\n",
    "for item in genderListCleared:\n",
    "    if item[1] == 'm':\n",
    "        mCount+=1\n",
    "    elif item[1] == 'f':\n",
    "        fCount+=1\n",
    "    elif item[1] == 'none':\n",
    "        nCount+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17803, 9695, 243852, 12900)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mCount,fCount,nCount,len(genderListCleared)-mCount-fCount-nCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17803, 9695, 243852, 12900)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mCount,fCount,nCount,len(genderListCleared)-mCount-fCount-nCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store data of Hindimonocorp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('genderListCleared', 'wb') as fp:\n",
    "    pickle.dump(genderListCleared, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('genderListCleared', 'rb') as fp:\n",
    "    genderListCleared = pickle.load(fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('एपिडेमिक', 'none'),\n",
       " ('धर्ममार्ग', 'none'),\n",
       " ('भैना', 'none'),\n",
       " ('जीवनानुभव', 'none'),\n",
       " ('सागरा', 'none'),\n",
       " ('कर्मेन्द्र', 'none'),\n",
       " ('प्रजोक्ट', 'none'),\n",
       " ('कज्जाक', 'none'),\n",
       " ('रोगिनी', 'none'),\n",
       " ('योर्', 'none')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genderListCleared[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "genderListNoNone= []\n",
    "for item in genderListCleared:\n",
    "    if item[1] == 'm':\n",
    "        genderListNoNone.append(item)\n",
    "    elif item[1] == 'f':\n",
    "        genderListNoNone.append(item)\n",
    "    elif item[1] == 'any':\n",
    "        genderListNoNone.append(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove none objects and store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('genderListNoNone', 'wb') as fp:\n",
    "    pickle.dump(genderListNoNone, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('genderListNoNone', 'rb') as fp:\n",
    "    genderListNoNone = pickle.load(fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "noneWords = list(set(genderListCleared)-set(genderListNoNone))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "noneWords = set([x[0] for x in noneWords])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data from hindi dependency tree. Mark objects that have more than one gender tag as any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'python' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-8eb7b4bb4a6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlingatagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenderlist\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgndrlist\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlingatagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtok\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlingatagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtagger\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumericTagger\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgenders2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgndrlist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\lingatagger\\lingatagger\\tagger.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \"\"\"\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Globally-importable utils.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[1;31m# resolution to succeed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[1;31m# pylint: disable=undefined-variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mpython\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[1;31m# pylint: enable=undefined-variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'python' is not defined"
     ]
    }
   ],
   "source": [
    "import lingatagger.genderlist as gndrlist\n",
    "import lingatagger.tokenizer as tok\n",
    "from lingatagger.tagger import numericTagger\n",
    "\n",
    "genders2 = gndrlist.drawlist()\n",
    "genderList2 = []\n",
    "for i in genders2:\n",
    "    x = i.split(\"\\t\")\n",
    "    if type(numericTagger(x[0])[0]) != tuple:\n",
    "        count = 0\n",
    "        for ch in list(x[0]):\n",
    "            if ch not in a:\n",
    "                count+=1\n",
    "        if count == 0:\n",
    "            if len(x)>=3:\n",
    "                genderList2.append((x[0],'any'))\n",
    "            else:\n",
    "                genderList2.append((x[0],x[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "genderList2.sort()\n",
    "genderList2Cleared = genderList2\n",
    "for ind in range(0, len(genderList2Cleared)-1):\n",
    "    if genderList2Cleared[ind][0] == genderList2Cleared[ind+1][0]:\n",
    "        genderList2Cleared[ind] = genderList2Cleared[ind][0], 'any'\n",
    "        genderList2Cleared[ind+1] = genderList2Cleared[ind][0], 'any'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "genderList2Cleared = mergedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('चिक', 'any')\n",
      "('निरस्त्रीकरण', 'any')\n",
      "('भूटानी', 'any')\n",
      "('दुधिया', 'any')\n",
      "('गुलाबी', 'any')\n",
      "('बरसाती', 'any')\n",
      "('ख़लासी', 'any')\n",
      "('कंचुकी', 'any')\n",
      "('छन', 'any')\n",
      "('गंजी', 'any')\n",
      "('टोंक', 'any')\n",
      "('हिंदुस्तानी', 'any')\n",
      "('लपेटन', 'any')\n",
      "('पंजाबी', 'any')\n",
      "('पीवर', 'any')\n",
      "('किलकिला', 'any')\n",
      "('नारंगी', 'any')\n",
      "('धाक', 'any')\n",
      "('नाक', 'any')\n",
      "('दह', 'any')\n",
      "('ओर', 'any')\n",
      "('काका', 'any')\n",
      "('फ्राँसीसी', 'any')\n",
      "('आस', 'any')\n",
      "('अमला', 'any')\n",
      "('गेरू', 'any')\n",
      "('उपेंद्र', 'any')\n",
      "('खान', 'any')\n",
      "('दाँग', 'any')\n",
      "('जरमन', 'any')\n",
      "('फ़सली', 'any')\n",
      "('फाँद', 'any')\n",
      "('झला', 'any')\n",
      "('कोली', 'any')\n",
      "('खगोलशास्त्री', 'any')\n",
      "('तोलन', 'any')\n",
      "('तरंग', 'any')\n",
      "('जापानी', 'any')\n",
      "('हिंदी', 'any')\n",
      "('केंचुल', 'any')\n",
      "('चूक', 'any')\n",
      "('मेला', 'any')\n",
      "('सिंहली', 'any')\n",
      "('विक्टोरिया', 'any')\n",
      "('मटिया', 'any')\n",
      "('शास्त्री', 'any')\n",
      "('बिहारी', 'any')\n",
      "('थू', 'any')\n",
      "('छाजन', 'any')\n",
      "('धमक', 'any')\n",
      "('कंपा', 'any')\n",
      "('क़वायद', 'any')\n",
      "('भौतिकशास्त्री', 'any')\n",
      "('पंथी', 'any')\n",
      "('याम', 'any')\n",
      "('मारवाड़ी', 'any')\n",
      "('बंगाली', 'any')\n",
      "('आब', 'any')\n",
      "('यहूदी', 'any')\n",
      "('तंत्री', 'any')\n",
      "('गाज', 'any')\n",
      "('ईसाई', 'any')\n",
      "('संविधि', 'any')\n",
      "('पाठा', 'any')\n",
      "('ज्योतिषी', 'any')\n",
      "('दृश', 'any')\n",
      "('उड़िया', 'any')\n",
      "('रटन', 'any')\n",
      "('टेम', 'any')\n",
      "('आर', 'any')\n",
      "('समाजशास्त्री', 'any')\n",
      "('जागा', 'any')\n",
      "('पुर्तगाली', 'any')\n",
      "('ठान', 'any')\n",
      "('टंका', 'any')\n",
      "('आसामी', 'any')\n",
      "('पंड', 'any')\n",
      "('अनुहार', 'any')\n",
      "('जमाई', 'any')\n",
      "('तमिल', 'any')\n",
      "('ओक', 'any')\n",
      "('दक्खिनी', 'any')\n",
      "('वंडर', 'any')\n",
      "('जक', 'any')\n",
      "('पनवाड़ी', 'any')\n",
      "('मलयाली', 'any')\n",
      "('बूढ़ा', 'any')\n",
      "('कलोल', 'any')\n",
      "('बँगला', 'any')\n",
      "('मोती', 'any')\n",
      "('गोत', 'any')\n",
      "('टोप', 'any')\n",
      "('घाट', 'any')\n"
     ]
    }
   ],
   "source": [
    "mCount2 = 0\n",
    "fCount2 = 0\n",
    "mergedList = list(set(mergedList))\n",
    "for item in mergedList:\n",
    "    if item[1] == 'm':\n",
    "        mCount2+=1\n",
    "    elif item[1] == 'f':\n",
    "        fCount2+=1\n",
    "    else:\n",
    "        print(item)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8320, 5713, 93)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mCount2,fCount2,len(mergedList)-mCount2-fCount2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save hindi dependency tree corpus after clearing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('genderList2Cleared', 'wb') as fp:\n",
    "    pickle.dump(genderList2Cleared, fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove words that are marked as any in hindi dependency tree but marked as none from hindi mono corp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "genderList2Matched = []\n",
    "for item in genderList2Cleared:\n",
    "    if item[0] in noneWords:\n",
    "        continue\n",
    "    genderList2Matched.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genderList2Cleared)-len(genderList2Matched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this new list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('genderList2Matched', 'wb') as fp:\n",
    "    pickle.dump(genderList2Matched, fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the two sets and create a new corpus with 60:20:20 split for train:validation:test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'genderListNoNone' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-84337b21949b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgenderList2Matched\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmergedList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgenderListNoNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mmergedList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmergedList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmergedList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'genderListNoNone' is not defined"
     ]
    }
   ],
   "source": [
    "mergedList = []\n",
    "for item in genderList2Matched:\n",
    "    mergedList.append((item[0], item[1]))\n",
    "for item in genderListNoNone:\n",
    "    mergedList.append((item[0], item[1]))\n",
    "mergedList = list(set(mergedList))\n",
    "mergedList.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mergedListCopy = []\n",
    "\n",
    "for ind in range(1, len(mergedList)-1):\n",
    "    if mergedList[ind][0] == mergedList[ind+1][0] and mergedList[ind][1] != mergedList[ind+1][1]:\n",
    "        #print(mergedList[ind][0], mergedList[ind][1], mergedList[ind][2], mergedList[ind+1][1])\n",
    "        continue\n",
    "    if mergedList[ind-1][0] == mergedList[ind][0] and mergedList[ind][1] != mergedList[ind-1][1]:\n",
    "        continue\n",
    "        \n",
    "    mergedListCopy.append(mergedList[ind])\n",
    "\n",
    "mergedList = mergedListCopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mergedList' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2b9e48afa781>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmergedList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmergedList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mergedList' is not defined"
     ]
    }
   ],
   "source": [
    "len(mergedList), len(set(mergedList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mergedList', 'wb') as fp:\n",
    "    pickle.dump(mergedList, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('t2', 'rb') as fp:\n",
    "    finalList = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3874"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('femaleExtra', 'rb') as fp:\n",
    "    femaleExtra = pickle.load(fp)\n",
    "len(femaleExtra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedList = finalList+femaleExtra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16734, 14126, 15447)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mergedList),len(set(mergedList)),len(set(finalList)) + len(set(femaleExtra))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define encoding function and create train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def encodex(text):\n",
    "    s = list(text)\n",
    "    \n",
    "    indices = []\n",
    "    for i in s:\n",
    "        indices.append(valid_hindi.index(i))\n",
    "    encoded = np.zeros([18, len(valid_hindi)+1], dtype=\"int\")\n",
    "    #print(len(a)+1)\n",
    "    k = 0\n",
    "    for i in indices:\n",
    "        encoded[k][i] = 1\n",
    "        k = k + 1\n",
    "    for i in range(18-len(list(s))):\n",
    "        encoded[k+i][len(valid_hindi)] = 1\n",
    "    return encoded\n",
    "\n",
    "def encodey(text):\n",
    "    if text == \"f\":\n",
    "        return [1]#,0,0]\n",
    "    elif text == \"m\":\n",
    "        return [0]#,0,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train and test sets for use in CNN and LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = []\n",
    "y = []\n",
    "for i in mergedList:\n",
    "    if len(i[0]) > 18:\n",
    "        continue\n",
    "    if(i[1] == 'any'):\n",
    "        continue\n",
    "    x.append(encodex(i[0]))\n",
    "    y.append(encodey(i[1]))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(x)\n",
    "Y = np.array(y)\n",
    "order = np.random.permutation(X.shape[0])\n",
    "np.take(X,order,axis=0,out=X)\n",
    "np.take(Y,order,axis=0,out=Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000300462712577"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save these sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X', 'wb') as fp:\n",
    "    pickle.dump(X, fp)\n",
    "\n",
    "with open('Y', 'wb') as fp:\n",
    "    pickle.dump(Y, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textstat\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/78/a050fa0f13c04db10c891167204e2cd0c0ae1be40842a10eaf5348360f94/textstat-0.5.4.tar.gz\n",
      "Collecting pyphen (from textstat)\n",
      "  Downloading https://files.pythonhosted.org/packages/15/82/08a3629dce8d1f3d91db843bb36d4d7db6b6269d5067259613a0d5c8a9db/Pyphen-0.9.5-py2.py3-none-any.whl (3.0MB)\n",
      "Collecting repoze.lru (from textstat)\n",
      "  Downloading https://files.pythonhosted.org/packages/b0/30/6cc0c95f0b59ad4b3b9163bff7cdcf793cc96fac64cf398ff26271f5cf5e/repoze.lru-0.7-py3-none-any.whl\n",
      "Building wheels for collected packages: textstat\n",
      "  Running setup.py bdist_wheel for textstat: started\n",
      "  Running setup.py bdist_wheel for textstat: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\archi\\AppData\\Local\\pip\\Cache\\wheels\\04\\ac\\d7\\a05c0ad7825899f11eacd5f9a5a78534808c8159281e65863c\n",
      "Successfully built textstat\n",
      "Installing collected packages: pyphen, repoze.lru, textstat\n",
      "Successfully installed pyphen-0.9.5 repoze.lru-0.7 textstat-0.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install textstat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
